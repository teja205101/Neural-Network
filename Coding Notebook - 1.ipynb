{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p_-fZOQLRupN"
   },
   "source": [
    "**IRIS DATASET**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2641,
     "status": "ok",
     "timestamp": 1725362072129,
     "user": {
      "displayName": "Justin Joseph",
      "userId": "11742605310338039771"
     },
     "user_tz": -330
    },
    "id": "pgkctMBMREXD"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Load dataset\n",
    "data = load_iris()\n",
    "X, y = data.data, data.target\n",
    "\n",
    "# One-hot encode the target labels\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "y = encoder.fit_transform(y.reshape(-1, 1))\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uXgdDPvuRAFK"
   },
   "source": [
    "**CREATE NEURAL NETWORK FROM SCRATCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1725362072130,
     "user": {
      "displayName": "Justin Joseph",
      "userId": "11742605310338039771"
     },
     "user_tz": -330
    },
    "id": "oaLYk90tRHTS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "class SimpleNN:\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, learning_rate=0.01):\n",
    "        # Initialize weights and biases\n",
    "        self.W1 = np.random.randn(input_dim, hidden_dim)\n",
    "        self.b1 = np.zeros((1, hidden_dim))\n",
    "        self.W2 = np.random.randn(hidden_dim, output_dim)\n",
    "        self.b2 = np.zeros((1, output_dim))\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return 1 / (1 + np.exp(-z))\n",
    "\n",
    "    def sigmoid_derivative(self, z):\n",
    "        return z * (1 - z)\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.z1 = np.dot(X, self.W1) + self.b1\n",
    "        self.a1 = self.sigmoid(self.z1)\n",
    "        self.z2 = np.dot(self.a1, self.W2) + self.b2\n",
    "        self.a2 = self.sigmoid(self.z2)\n",
    "        return self.a2\n",
    "\n",
    "    def backward(self, X, y, output):\n",
    "        error = output - y\n",
    "        d_output = error * self.sigmoid_derivative(output)\n",
    "\n",
    "        error_hidden = d_output.dot(self.W2.T)\n",
    "        d_hidden = error_hidden * self.sigmoid_derivative(self.a1)\n",
    "\n",
    "        self.W2 -= self.a1.T.dot(d_output) * self.learning_rate\n",
    "        self.b2 -= np.sum(d_output, axis=0, keepdims=True) * self.learning_rate\n",
    "        self.W1 -= X.T.dot(d_hidden) * self.learning_rate\n",
    "        self.b1 -= np.sum(d_hidden, axis=0, keepdims=True) * self.learning_rate\n",
    "\n",
    "    def train(self, X, y, epochs=1000):\n",
    "        for _ in range(epochs):\n",
    "            output = self.forward(X)\n",
    "            self.backward(X, y, output)\n",
    "\n",
    "    def predict(self, X):\n",
    "        output = self.forward(X)\n",
    "        return np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3264,
     "status": "ok",
     "timestamp": 1725362075392,
     "user": {
      "displayName": "Justin Joseph",
      "userId": "11742605310338039771"
     },
     "user_tz": -330
    },
    "id": "vQKFqtCRRITF",
    "outputId": "c600117d-8ca7-4d11-a8fc-1300bdb283ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from Model: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Initialize the neural network\n",
    "input_dim = X_train.shape[1]\n",
    "hidden_dim = 10\n",
    "output_dim = y_train.shape[1]\n",
    "model = SimpleNN(input_dim, hidden_dim, output_dim, learning_rate=0.01)\n",
    "\n",
    "# Train the model\n",
    "model.train(X_train, y_train, epochs=10000)\n",
    "\n",
    "# Inference\n",
    "y_pred = model.predict(X_test)\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = accuracy_score(y_true, y_pred)\n",
    "print(f\"Accuracy from Model: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XV5bIWW5RR1N"
   },
   "source": [
    "**CREATE NEURAL NETWORK USING TENSORFLOW**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 15886,
     "status": "ok",
     "timestamp": 1725362091276,
     "user": {
      "displayName": "Justin Joseph",
      "userId": "11742605310338039771"
     },
     "user_tz": -330
    },
    "id": "tePdoF8gRLOW"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "# Define the model\n",
    "tf_model = models.Sequential([\n",
    "    layers.Input(shape=(input_dim,)),\n",
    "    layers.Dense(hidden_dim, activation='sigmoid'),\n",
    "    layers.Dense(output_dim, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "tf_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18405,
     "status": "ok",
     "timestamp": 1725362168020,
     "user": {
      "displayName": "Justin Joseph",
      "userId": "11742605310338039771"
     },
     "user_tz": -330
    },
    "id": "b9U_xyyfRYia",
    "outputId": "f032556d-4730-4f39-99b1-28427512c14f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 850ms/step - accuracy: 0.3529 - loss: 1.1240 - val_accuracy: 0.3667 - val_loss: 1.1268\n",
      "Epoch 2/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2842 - loss: 1.1433 - val_accuracy: 0.3667 - val_loss: 1.1232\n",
      "Epoch 3/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3165 - loss: 1.1300 - val_accuracy: 0.3667 - val_loss: 1.1196\n",
      "Epoch 4/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3133 - loss: 1.1306 - val_accuracy: 0.3667 - val_loss: 1.1163\n",
      "Epoch 5/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3342 - loss: 1.1182 - val_accuracy: 0.3667 - val_loss: 1.1130\n",
      "Epoch 6/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.2852 - loss: 1.1268 - val_accuracy: 0.3667 - val_loss: 1.1099\n",
      "Epoch 7/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3175 - loss: 1.1164 - val_accuracy: 0.3667 - val_loss: 1.1067\n",
      "Epoch 8/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.3060 - loss: 1.1147 - val_accuracy: 0.3667 - val_loss: 1.1036\n",
      "Epoch 9/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.3227 - loss: 1.1079 - val_accuracy: 0.3667 - val_loss: 1.1007\n",
      "Epoch 10/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.2842 - loss: 1.1091 - val_accuracy: 0.3667 - val_loss: 1.0977\n",
      "Epoch 11/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.2935 - loss: 1.1061 - val_accuracy: 0.3667 - val_loss: 1.0946\n",
      "Epoch 12/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3363 - loss: 1.0942 - val_accuracy: 0.3667 - val_loss: 1.0916\n",
      "Epoch 13/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3029 - loss: 1.0961 - val_accuracy: 0.3667 - val_loss: 1.0885\n",
      "Epoch 14/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.3602 - loss: 1.0844 - val_accuracy: 0.3667 - val_loss: 1.0856\n",
      "Epoch 15/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3250 - loss: 1.0856 - val_accuracy: 0.3667 - val_loss: 1.0826\n",
      "Epoch 16/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3417 - loss: 1.0799 - val_accuracy: 0.3667 - val_loss: 1.0795\n",
      "Epoch 17/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3294 - loss: 1.0787 - val_accuracy: 0.4333 - val_loss: 1.0764\n",
      "Epoch 18/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.3452 - loss: 1.0742 - val_accuracy: 0.4333 - val_loss: 1.0733\n",
      "Epoch 19/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4054 - loss: 1.0719 - val_accuracy: 0.4333 - val_loss: 1.0701\n",
      "Epoch 20/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5408 - loss: 1.0651 - val_accuracy: 0.5667 - val_loss: 1.0668\n",
      "Epoch 21/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6279 - loss: 1.0639 - val_accuracy: 0.6000 - val_loss: 1.0635\n",
      "Epoch 22/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6554 - loss: 1.0633 - val_accuracy: 0.6000 - val_loss: 1.0602\n",
      "Epoch 23/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7108 - loss: 1.0557 - val_accuracy: 0.6333 - val_loss: 1.0568\n",
      "Epoch 24/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6906 - loss: 1.0547 - val_accuracy: 0.7000 - val_loss: 1.0532\n",
      "Epoch 25/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7792 - loss: 1.0491 - val_accuracy: 0.7000 - val_loss: 1.0496\n",
      "Epoch 26/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7890 - loss: 1.0479 - val_accuracy: 0.7667 - val_loss: 1.0460\n",
      "Epoch 27/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7758 - loss: 1.0414 - val_accuracy: 0.8000 - val_loss: 1.0423\n",
      "Epoch 28/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7592 - loss: 1.0405 - val_accuracy: 0.7333 - val_loss: 1.0386\n",
      "Epoch 29/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7985 - loss: 1.0338 - val_accuracy: 0.7000 - val_loss: 1.0347\n",
      "Epoch 30/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7740 - loss: 1.0304 - val_accuracy: 0.7000 - val_loss: 1.0308\n",
      "Epoch 31/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7585 - loss: 1.0275 - val_accuracy: 0.7000 - val_loss: 1.0267\n",
      "Epoch 32/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7831 - loss: 1.0226 - val_accuracy: 0.6333 - val_loss: 1.0227\n",
      "Epoch 33/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.7331 - loss: 1.0189 - val_accuracy: 0.6667 - val_loss: 1.0183\n",
      "Epoch 34/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7285 - loss: 1.0156 - val_accuracy: 0.6333 - val_loss: 1.0142\n",
      "Epoch 35/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7433 - loss: 1.0078 - val_accuracy: 0.6333 - val_loss: 1.0098\n",
      "Epoch 36/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7225 - loss: 1.0056 - val_accuracy: 0.6333 - val_loss: 1.0053\n",
      "Epoch 37/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7475 - loss: 1.0011 - val_accuracy: 0.6333 - val_loss: 1.0006\n",
      "Epoch 38/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7517 - loss: 0.9933 - val_accuracy: 0.6333 - val_loss: 0.9959\n",
      "Epoch 39/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7360 - loss: 0.9937 - val_accuracy: 0.6333 - val_loss: 0.9912\n",
      "Epoch 40/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.7048 - loss: 0.9920 - val_accuracy: 0.6333 - val_loss: 0.9864\n",
      "Epoch 41/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7527 - loss: 0.9793 - val_accuracy: 0.6333 - val_loss: 0.9813\n",
      "Epoch 42/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.6775 - loss: 0.9822 - val_accuracy: 0.6333 - val_loss: 0.9759\n",
      "Epoch 43/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7402 - loss: 0.9745 - val_accuracy: 0.6333 - val_loss: 0.9707\n",
      "Epoch 44/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7277 - loss: 0.9618 - val_accuracy: 0.6333 - val_loss: 0.9652\n",
      "Epoch 45/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7108 - loss: 0.9625 - val_accuracy: 0.6333 - val_loss: 0.9598\n",
      "Epoch 46/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7287 - loss: 0.9598 - val_accuracy: 0.6333 - val_loss: 0.9543\n",
      "Epoch 47/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7069 - loss: 0.9603 - val_accuracy: 0.6333 - val_loss: 0.9485\n",
      "Epoch 48/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7025 - loss: 0.9503 - val_accuracy: 0.6333 - val_loss: 0.9423\n",
      "Epoch 49/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7352 - loss: 0.9339 - val_accuracy: 0.7000 - val_loss: 0.9358\n",
      "Epoch 50/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7744 - loss: 0.9259 - val_accuracy: 0.6667 - val_loss: 0.9294\n",
      "Epoch 51/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7627 - loss: 0.9312 - val_accuracy: 0.7000 - val_loss: 0.9225\n",
      "Epoch 52/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.6981 - loss: 0.9249 - val_accuracy: 0.7000 - val_loss: 0.9152\n",
      "Epoch 53/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.7694 - loss: 0.9059 - val_accuracy: 0.7000 - val_loss: 0.9076\n",
      "Epoch 54/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8069 - loss: 0.9015 - val_accuracy: 0.7333 - val_loss: 0.8998\n",
      "Epoch 55/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.7862 - loss: 0.8885 - val_accuracy: 0.7667 - val_loss: 0.8913\n",
      "Epoch 56/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8052 - loss: 0.8911 - val_accuracy: 0.7667 - val_loss: 0.8828\n",
      "Epoch 57/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7667 - loss: 0.8856 - val_accuracy: 0.8000 - val_loss: 0.8740\n",
      "Epoch 58/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8023 - loss: 0.8772 - val_accuracy: 0.8667 - val_loss: 0.8644\n",
      "Epoch 59/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8210 - loss: 0.8579 - val_accuracy: 0.8667 - val_loss: 0.8547\n",
      "Epoch 60/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.7785 - loss: 0.8696 - val_accuracy: 0.9000 - val_loss: 0.8451\n",
      "Epoch 61/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8392 - loss: 0.8427 - val_accuracy: 0.9333 - val_loss: 0.8350\n",
      "Epoch 62/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8119 - loss: 0.8331 - val_accuracy: 0.9000 - val_loss: 0.8251\n",
      "Epoch 63/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8279 - loss: 0.8159 - val_accuracy: 0.9000 - val_loss: 0.8147\n",
      "Epoch 64/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8302 - loss: 0.8241 - val_accuracy: 0.9000 - val_loss: 0.8048\n",
      "Epoch 65/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8315 - loss: 0.8143 - val_accuracy: 0.9333 - val_loss: 0.7951\n",
      "Epoch 66/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8285 - loss: 0.8017 - val_accuracy: 0.9333 - val_loss: 0.7859\n",
      "Epoch 67/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8242 - loss: 0.7874 - val_accuracy: 0.9333 - val_loss: 0.7767\n",
      "Epoch 68/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8769 - loss: 0.7752 - val_accuracy: 0.9333 - val_loss: 0.7676\n",
      "Epoch 69/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8727 - loss: 0.7742 - val_accuracy: 0.9000 - val_loss: 0.7593\n",
      "Epoch 70/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8777 - loss: 0.7569 - val_accuracy: 0.9333 - val_loss: 0.7513\n",
      "Epoch 71/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8594 - loss: 0.7520 - val_accuracy: 0.9000 - val_loss: 0.7432\n",
      "Epoch 72/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8938 - loss: 0.7463 - val_accuracy: 0.9333 - val_loss: 0.7358\n",
      "Epoch 73/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8656 - loss: 0.7407 - val_accuracy: 0.9333 - val_loss: 0.7284\n",
      "Epoch 74/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8794 - loss: 0.7333 - val_accuracy: 0.9333 - val_loss: 0.7209\n",
      "Epoch 75/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8835 - loss: 0.7169 - val_accuracy: 0.9333 - val_loss: 0.7140\n",
      "Epoch 76/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8846 - loss: 0.7019 - val_accuracy: 0.9333 - val_loss: 0.7070\n",
      "Epoch 77/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.9015 - loss: 0.6966 - val_accuracy: 0.9333 - val_loss: 0.7007\n",
      "Epoch 78/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9075 - loss: 0.6944 - val_accuracy: 0.9333 - val_loss: 0.6947\n",
      "Epoch 79/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8658 - loss: 0.6955 - val_accuracy: 0.9333 - val_loss: 0.6885\n",
      "Epoch 80/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9038 - loss: 0.6929 - val_accuracy: 0.9333 - val_loss: 0.6828\n",
      "Epoch 81/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8723 - loss: 0.6781 - val_accuracy: 0.9333 - val_loss: 0.6767\n",
      "Epoch 82/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9244 - loss: 0.6692 - val_accuracy: 0.9333 - val_loss: 0.6709\n",
      "Epoch 83/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9102 - loss: 0.6885 - val_accuracy: 0.9333 - val_loss: 0.6652\n",
      "Epoch 84/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8988 - loss: 0.6688 - val_accuracy: 0.9667 - val_loss: 0.6594\n",
      "Epoch 85/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8988 - loss: 0.6730 - val_accuracy: 0.9667 - val_loss: 0.6540\n",
      "Epoch 86/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8894 - loss: 0.6617 - val_accuracy: 0.9667 - val_loss: 0.6488\n",
      "Epoch 87/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9123 - loss: 0.6554 - val_accuracy: 0.9667 - val_loss: 0.6431\n",
      "Epoch 88/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9388 - loss: 0.6364 - val_accuracy: 0.9667 - val_loss: 0.6382\n",
      "Epoch 89/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9200 - loss: 0.6480 - val_accuracy: 0.9667 - val_loss: 0.6335\n",
      "Epoch 90/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9148 - loss: 0.6418 - val_accuracy: 0.9667 - val_loss: 0.6284\n",
      "Epoch 91/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9294 - loss: 0.6285 - val_accuracy: 0.9667 - val_loss: 0.6235\n",
      "Epoch 92/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9179 - loss: 0.6327 - val_accuracy: 0.9667 - val_loss: 0.6190\n",
      "Epoch 93/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9242 - loss: 0.6076 - val_accuracy: 0.9667 - val_loss: 0.6145\n",
      "Epoch 94/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9419 - loss: 0.6009 - val_accuracy: 0.9667 - val_loss: 0.6104\n",
      "Epoch 95/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9325 - loss: 0.6095 - val_accuracy: 0.9667 - val_loss: 0.6064\n",
      "Epoch 96/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9065 - loss: 0.6160 - val_accuracy: 0.9667 - val_loss: 0.6021\n",
      "Epoch 97/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9273 - loss: 0.6219 - val_accuracy: 0.9667 - val_loss: 0.5984\n",
      "Epoch 98/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9504 - loss: 0.5884 - val_accuracy: 0.9667 - val_loss: 0.5943\n",
      "Epoch 99/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9098 - loss: 0.6179 - val_accuracy: 0.9667 - val_loss: 0.5905\n",
      "Epoch 100/100\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9296 - loss: 0.6110 - val_accuracy: 0.9667 - val_loss: 0.5865\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x78ef600710c0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define a callback for saving the model\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint('tf_model.h5.keras', save_best_only=True)\n",
    "\n",
    "# Train the model\n",
    "tf_model.fit(X_train, y_train, epochs=100, validation_data=(X_test, y_test), callbacks=[checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2142,
     "status": "ok",
     "timestamp": 1725362196080,
     "user": {
      "displayName": "Justin Joseph",
      "userId": "11742605310338039771"
     },
     "user_tz": -330
    },
    "id": "F5rCI0zxRaxM",
    "outputId": "2a9ece4f-4bf1-422d-f77f-180aef89163f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 - 1s - 1s/step - accuracy: 0.9667 - loss: 0.5865\n",
      "Accuracy from TensorFlow Model: 96.67%\n"
     ]
    }
   ],
   "source": [
    "# Load the best saved model\n",
    "best_tf_model = tf.keras.models.load_model('tf_model.h5.keras')\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = best_tf_model.evaluate(X_test, y_test, verbose=2)\n",
    "print(f\"Accuracy from TensorFlow Model: {test_acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4gVjYFJfRnAE"
   },
   "source": [
    "**CREATE NEURAL NETWORK USING PYTORCH**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "executionInfo": {
     "elapsed": 7178,
     "status": "ok",
     "timestamp": 1725362207317,
     "user": {
      "displayName": "Justin Joseph",
      "userId": "11742605310338039771"
     },
     "user_tz": -330
    },
    "id": "7Hht5GjsRc7R"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert data to tensors\n",
    "X_train_tensor = torch.Tensor(X_train)\n",
    "y_train_tensor = torch.Tensor(np.argmax(y_train, axis=1)).long()\n",
    "X_test_tensor = torch.Tensor(X_test)\n",
    "y_test_tensor = torch.Tensor(np.argmax(y_test, axis=1)).long()\n",
    "\n",
    "# Create DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "# Define the model\n",
    "class PyTorchNN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(PyTorchNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sigmoid(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "pt_model = PyTorchNN(input_dim, hidden_dim, output_dim)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(pt_model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1725362207927,
     "user": {
      "displayName": "Justin Joseph",
      "userId": "11742605310338039771"
     },
     "user_tz": -330
    },
    "id": "Pq03-Ek_Rgec",
    "outputId": "729633fa-ee4f-466f-930e-35db0ff6dc00"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy from PyTorch Model: 100.00%\n"
     ]
    }
   ],
   "source": [
    "# Define a callback to save the model\n",
    "best_acc = 0.0\n",
    "for epoch in range(100):\n",
    "    pt_model.train()\n",
    "    for X_batch, y_batch in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        output = pt_model(X_batch)\n",
    "        loss = criterion(output, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    pt_model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_output = pt_model(X_test_tensor)\n",
    "        _, y_pred_tensor = torch.max(test_output, 1)\n",
    "        accuracy = (y_pred_tensor == y_test_tensor).sum().item() / len(y_test_tensor)\n",
    "\n",
    "    # Save the best model\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        torch.save(pt_model.state_dict(), 'pt_model.pth')\n",
    "\n",
    "print(f\"Accuracy from PyTorch Model: {best_acc * 100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "authorship_tag": "ABX9TyMytudb4WXj+1FyWcZK1ds9",
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
